{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e01ec09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def read_excel_files_from_zipfile(zip_file_path, folder_path):\n",
    "    dfs = {}\n",
    "    with zipfile.ZipFile(zip_file_path) as zf:\n",
    "        for subfile in zf.namelist():\n",
    "            if subfile.startswith('DRAS') and subfile.endswith('.xlsx'):\n",
    "                # Read Excel file into pandas dataframe\n",
    "                with zf.open(subfile) as f:\n",
    "                    df = pd.read_excel(f, header=None)\n",
    "                    # Add folder path to dataframe\n",
    "                    df['Folder_Path'] = folder_path\n",
    "                    dfs[subfile] = df\n",
    "            elif subfile.endswith('.zip'):\n",
    "                # Recursively read Excel files from nested zip file\n",
    "                nested_zip_path = zf.extract(subfile)\n",
    "                nested_dfs = read_excel_files_from_zipfile(nested_zip_path, folder_path)\n",
    "                dfs.update(nested_dfs)\n",
    "                os.remove(nested_zip_path)  # remove extracted zip file\n",
    "    return dfs\n",
    "\n",
    "\n",
    "# Define folder path\n",
    "folder_path = r'E:\\Techniplant'\n",
    "\n",
    "# Define dictionary to store dataframes\n",
    "dfs = {}\n",
    "\n",
    "# Loop over all files and subfolders in folder path\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.zip'):\n",
    "            zip_file_path = os.path.join(root, file)\n",
    "            # Add folder path to read_excel_files_from_zipfile function call\n",
    "            dfs.update(read_excel_files_from_zipfile(zip_file_path, root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "d2f73dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 ='Description'\n",
    "word2='Rev.'\n",
    "word3='Issued by (Contractor Discipline)'\n",
    "word4='in reply to CONTRACTOR Transmittal Document'\n",
    "description=[]\n",
    "rev=[]\n",
    "discipline=[]\n",
    "transmittal=[]\n",
    "date=[]\n",
    "names=[]\n",
    "folder_pathh =[]\n",
    "for name, data in dfs.items():\n",
    "    names.append(name)\n",
    "    try:\n",
    "        row=data.loc[(data.values==word1).any(1), (data.values==word1).any(0)].index[0]\n",
    "        column=data.loc[(data.values==word1).any(1), (data.values==word1).any(0)].columns[0]\n",
    "        description.append(data.loc[row,column+1])\n",
    "    except:\n",
    "        description.append(np.nan)\n",
    "    try:\n",
    "        row=data.loc[(data.values==word2).any(1), (data.values==word2).any(0)].index[0]\n",
    "        column=data.loc[(data.values==word2).any(1), (data.values==word2).any(0)].columns[0]\n",
    "        rev.append(data.loc[row,column+1])\n",
    "    except:\n",
    "        rev.append(np.nan)\n",
    "    try:\n",
    "        row=data.loc[(data.values==word3).any(1), (data.values==word3).any(0)].index[0]\n",
    "        column=data.loc[(data.values==word3).any(1), (data.values==word3).any(0)].columns[0]\n",
    "        discipline.append(data.loc[row,column+1])\n",
    "    except:\n",
    "        discipline.append(np.nan)\n",
    "    try:\n",
    "        row=data.loc[(data.values==word4).any(1), (data.values==word4).any(0)].index[0]\n",
    "        column=data.loc[(data.values==word4).any(1), (data.values==word4).any(0)].columns[0]\n",
    "        transmittal.append(data.loc[row+1,column+1])\n",
    "    except:\n",
    "        transmittal.append(np.nan)\n",
    "    try:\n",
    "        row=data.loc[(data.values==word4).any(1), (data.values==word4).any(0)].index[0]\n",
    "        column=data.loc[(data.values==word4).any(1), (data.values==word4).any(0)].columns[0]\n",
    "        date.append(data.loc[row+2,column+1])\n",
    "    except:\n",
    "        date.append(np.nan)\n",
    "    try:\n",
    "        pathh=data.iloc[2,-1]\n",
    "        folder_pathh.append(pathh)\n",
    "    except:\n",
    "        folder_pathh.append(np.nan)\n",
    "        \n",
    "    \n",
    "\n",
    "df_info=pd.DataFrame({'DRAS name':names, 'Descriptipn':description, 'REV': rev, 'Discipline':discipline, 'Transmittal':transmittal\n",
    "                     , 'Date':date, 'folder_path': folder_pathh})\n",
    "df_info['UNIT']=df_info['DRAS name'].str.split('-',expand=True)[1]\n",
    "df_info['Techniplant_Page_number'] = df_info['folder_path'].str.split('\\\\', expand=True).iloc[:, -1]     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "0194c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info.to_excel('revamp.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17076087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2202353c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e91bf2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c8947b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04282f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d02524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0dc441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1f77ce9",
   "metadata": {},
   "source": [
    "### Works well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3660fc",
   "metadata": {},
   "source": [
    "#### print all excel files that starts with dras inside specefic folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cedbd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "folder_path = r\"E:\\Techniplant\\2\\5\"\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".zip\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with zipfile.ZipFile(file_path) as zf:\n",
    "            for inner_file in zf.namelist():\n",
    "                if inner_file.startswith('DRAS') and inner_file.endswith('.xlsx'):\n",
    "                    print(f\"Excel file {inner_file} found in {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b654d",
   "metadata": {},
   "source": [
    "### Works Well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67fc60",
   "metadata": {},
   "source": [
    "#### read all excel file inside a single zipped file and convert them to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fae42ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dir_path = r'E:\\Techniplant\\2\\5\\2544_20221028204153.zip'\n",
    "\n",
    "dfs = {}  # Empty dictionary to store dataframes\n",
    "\n",
    "with zipfile.ZipFile(dir_path, 'r') as zipf:\n",
    "    for file in zipf.namelist():\n",
    "        if file.startswith('DRAS') and file.endswith('.xlsx'):\n",
    "            with zipf.open(file) as f:\n",
    "                dfs[file] = pd.read_excel(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472b6544",
   "metadata": {},
   "source": [
    "### Works Well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d9c62b",
   "metadata": {},
   "source": [
    "#### read all excel files inside zipped files that start with DRAS and end with .xlsx and convert All to dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaeb27a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "# Define folder path\n",
    "folder_path = r'E:\\Techniplant\\2'\n",
    "\n",
    "# Define dictionary to store dataframes\n",
    "dfs = {}\n",
    "\n",
    "# Loop over all files and subfolders in folder path\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.zip'):\n",
    "            # Read Excel files from zip file\n",
    "            with zipfile.ZipFile(os.path.join(root, file)) as zf:\n",
    "                for subfile in zf.namelist():\n",
    "                    if subfile.startswith('DRAS') and subfile.endswith('.xlsx'):\n",
    "                        # Read Excel file into pandas dataframe\n",
    "                        with zf.open(subfile) as f:\n",
    "                            df = pd.read_excel(f,header=None)\n",
    "                            dfs[subfile] = df\n",
    "                            print(os.path.basename(root))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6db81f6",
   "metadata": {},
   "source": [
    "### Works Well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a56a67",
   "metadata": {},
   "source": [
    "#### this code recrusively search for every zipfile inside zipefile and update dfs accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f69ba16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def read_excel_files_from_zipfile(zip_file_path):\n",
    "    dfs = {}\n",
    "    with zipfile.ZipFile(zip_file_path) as zf:\n",
    "        for subfile in zf.namelist():\n",
    "            if subfile.startswith('DRAS') and subfile.endswith('.xlsx'):\n",
    "                # Read Excel file into pandas dataframe\n",
    "                with zf.open(subfile) as f:\n",
    "                    df = pd.read_excel(f, header=None)\n",
    "                    dfs[subfile] = df\n",
    "            elif subfile.endswith('.zip'):\n",
    "                # Recursively read Excel files from nested zip file\n",
    "                nested_zip_path = zf.extract(subfile)\n",
    "                nested_dfs = read_excel_files_from_zipfile(nested_zip_path)\n",
    "                dfs.update(nested_dfs)\n",
    "    return dfs\n",
    "\n",
    "\n",
    "# Define folder path\n",
    "folder_path = r'E:\\Techniplant\\2'\n",
    "\n",
    "# Define dictionary to store dataframes\n",
    "dfs = {}\n",
    "\n",
    "# Loop over all files and subfolders in folder path\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.zip'):\n",
    "            zip_file_path = os.path.join(root, file)\n",
    "            dfs.update(read_excel_files_from_zipfile(zip_file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1837f3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1aa50a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a04d97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
